{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "BASE = 'https://www.indeed.com/'\n",
    "FIRST_LISTING_PAGE = 'https://www.indeed.com/cmp/Pnc-Financial-Services-Group/jobs?clearPrefilter=1'\n",
    "LISTING_URL_PREFIX = 'https://www.indeed.com/cmp/Pnc-Financial-Services-Group/jobs?start='\n",
    "LISTING_URL_POSTFIX = 'clearPrefilter=1#cmp-menu-container'\n",
    "\n",
    "\n",
    "def scrape(postingUrl,bank):\n",
    "    print(postingUrl)\n",
    "    global count\n",
    "    headers = [\"Job No\", \"Institution\", \"List Id {1,2,3}\", \"URL (URL of the job posting)\"]\n",
    "\n",
    "    values = [count, \"PNC Bank\", \"2\", postingUrl]\n",
    "    \n",
    "    indices = list(range(1, 101))\n",
    "    \n",
    "    wordCountDict = dict.fromkeys(indices,0)\n",
    "    postingDict = dict(zip(headers, values))\n",
    "    \n",
    "    enc = 'utf-8'\n",
    "    with open(\"Data/frequency_final.csv\", 'r', encoding = enc) as f:\n",
    "        reader = csv.reader(f)\n",
    "        keywords = list(reader)\n",
    "    arr = [i[0] for i in keywords]\n",
    "    \n",
    "    try:\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        request = urllib2.Request(postingUrl,headers=hdr)\n",
    "        html_page = urlopen(request)\n",
    "        soup2 =  BeautifulSoup(html_page,\"html.parser\")\n",
    "        if bank == 'PNC':\n",
    "            value = soup2.find('input', {'id':'preLoadJSON'})\n",
    "            for word in value.get('value').split('\"CandLandPageText\"')[1].replace(\"\\\\u003\", \" \").split():\n",
    "                if(word in arr):\n",
    "                    ind = arr.index(word)\n",
    "                    wordCountDict[ind] = wordCountDict.get(ind, 0) + 1\n",
    "            dataDict = postingDict.copy()  \n",
    "            return {**postingDict, **wordCountDict}\n",
    "                \n",
    "        else:\n",
    "            value = soup2.findAll(\"div\", {\"class\": \"desc\"})\n",
    "            for val in value:\n",
    "                st = val.text.split()\n",
    "                for word in st:\n",
    "                    if(word in arr):\n",
    "                        ind = arr.index(word)\n",
    "                        wordCountDict[ind] = wordCountDict.get(ind, 0) + 1\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        return (\"An exception occurred\")\n",
    "    \n",
    "    count = count + 1\n",
    "\n",
    "    dataDict = postingDict.copy()  \n",
    "    return {**postingDict, **wordCountDict}\n",
    "\n",
    "def scrape_page_pnc(page):\n",
    "    response = urlopen(page)\n",
    "    bs_obj = BeautifulSoup(response, \"html.parser\")\n",
    "    if bs_obj:\n",
    "        links = bs_obj.findAll('div',{'class': 'cmp-section cmp-with-border'})\n",
    "        for page in links:\n",
    "            linkTags = page.find_all('a', attrs={'href': re.compile(\"/cmp/_\")})\n",
    "            for tag in linkTags:\n",
    "                link = tag.get('href')\n",
    "                postingUrl = BASE + link\n",
    "                pageDict = scrape(postingUrl,\"PNC\")\n",
    "                #if (type(pageDict) is dict):\n",
    "                        #data = pd.DataFrame([pageDict])\n",
    "                        # if file does not exist write header \n",
    "                        #if not os.path.isfile('pnc_desc.csv'):\n",
    "                            #data.to_csv('pnc_desc.csv', header='column_names')\n",
    "                        #else: \n",
    "                            # else it exists so append without writing the header\n",
    "                            #data.to_csv('pnc_desc.csv', mode='a', header=False)\n",
    "                #else:\n",
    "                    #print(\"exception?\")\n",
    "\n",
    "def get_data(bank,Url):\n",
    "    scrape_site(Url)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_data(\"PNC\",\"https://www.indeed.com/jobs?q=Pnc+Bank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
